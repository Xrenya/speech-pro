{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "asr_lab_4 (1).ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "68e7cab740684122a152081c2f5c1d16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_29f463fb5f874861908b4c6321b5d357",
       "IPY_MODEL_8d85bf7f668e4ee2bb7f195423b03938",
       "IPY_MODEL_7c72b70da2084161b5fe07559b14c14f"
      ],
      "layout": "IPY_MODEL_a04e20d12ff54be7b3e2766bbf271786"
     }
    },
    "29f463fb5f874861908b4c6321b5d357": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d44f4c58cb545dabeead938dc8d7234",
      "placeholder": "​",
      "style": "IPY_MODEL_3e6306872dca413382c40bf1344718b3",
      "value": "100%"
     }
    },
    "8d85bf7f668e4ee2bb7f195423b03938": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_734705263c894bc1b56436c0236bd330",
      "max": 6387309499,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d3bfee4d9ec641db98fa63fbb50ef19f",
      "value": 6387309499
     }
    },
    "7c72b70da2084161b5fe07559b14c14f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c5b6231d8a744b991c4e67f4749a38c",
      "placeholder": "​",
      "style": "IPY_MODEL_2a329bad709b4dfea8825ff6f837b9b3",
      "value": " 5.95G/5.95G [03:40&lt;00:00, 29.4MB/s]"
     }
    },
    "a04e20d12ff54be7b3e2766bbf271786": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d44f4c58cb545dabeead938dc8d7234": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e6306872dca413382c40bf1344718b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "734705263c894bc1b56436c0236bd330": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3bfee4d9ec641db98fa63fbb50ef19f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3c5b6231d8a744b991c4e67f4749a38c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a329bad709b4dfea8825ff6f837b9b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a26b892461224607bf240713328f09db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_131a9e3341854c13b62cbac41307e1e2",
       "IPY_MODEL_e35d5f449ad24375afc879563189f569",
       "IPY_MODEL_631a22999a6c463f8c21654ea485f8f8"
      ],
      "layout": "IPY_MODEL_9fcc8a5576034a52954708ca2e92b111"
     }
    },
    "131a9e3341854c13b62cbac41307e1e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebdc01d6ef184019847ae9b30995cedf",
      "placeholder": "​",
      "style": "IPY_MODEL_a0ea973d5d9544ba8176604e5ab31d60",
      "value": "100%"
     }
    },
    "e35d5f449ad24375afc879563189f569": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee499e8fc3594c9b91c1ca2b3471a0b4",
      "max": 346663984,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_32695a0c4c6040dabb3553cbb4c4f468",
      "value": 346663984
     }
    },
    "631a22999a6c463f8c21654ea485f8f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55b41144ccfd4c0c9c53001e5a4df7e4",
      "placeholder": "​",
      "style": "IPY_MODEL_bdc25eaef0c84cc293b1ba498555d44e",
      "value": " 331M/331M [00:14&lt;00:00, 29.6MB/s]"
     }
    },
    "9fcc8a5576034a52954708ca2e92b111": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebdc01d6ef184019847ae9b30995cedf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0ea973d5d9544ba8176604e5ab31d60": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee499e8fc3594c9b91c1ca2b3471a0b4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32695a0c4c6040dabb3553cbb4c4f468": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "55b41144ccfd4c0c9c53001e5a4df7e4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdc25eaef0c84cc293b1ba498555d44e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c38207ef5384c2886ba2fdd60c76345": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_86418589e09e4ff88273f9566bc5a572",
       "IPY_MODEL_621646e6502944978fbe3245a5b9bd26",
       "IPY_MODEL_53ea2ec7c43b40de9c29ea5d0dd48051"
      ],
      "layout": "IPY_MODEL_5c5a7aeb1f1b4180bb5d0148e09992ca"
     }
    },
    "86418589e09e4ff88273f9566bc5a572": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5d3e2a726fe4a9aae02ecbb72c22994",
      "placeholder": "​",
      "style": "IPY_MODEL_1e5858381d234fceab7cf558817ff7f7",
      "value": "100%"
     }
    },
    "621646e6502944978fbe3245a5b9bd26": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9dce63c148d642578794061ded216d68",
      "max": 6387309499,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b743bca428241f8a0973a4ca9371ed7",
      "value": 6387309499
     }
    },
    "53ea2ec7c43b40de9c29ea5d0dd48051": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef06afea9f4d48cdb5b7a8cf3800feb8",
      "placeholder": "​",
      "style": "IPY_MODEL_795d3831083748a6a8ad8f8f767bc549",
      "value": " 5.95G/5.95G [03:52&lt;00:00, 27.8MB/s]"
     }
    },
    "5c5a7aeb1f1b4180bb5d0148e09992ca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5d3e2a726fe4a9aae02ecbb72c22994": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e5858381d234fceab7cf558817ff7f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9dce63c148d642578794061ded216d68": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b743bca428241f8a0973a4ca9371ed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ef06afea9f4d48cdb5b7a8cf3800feb8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "795d3831083748a6a8ad8f8f767bc549": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "faae1db38242454fa5003c3c3e8e229a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15afa0cc59494ff78d84b269c9846ab7",
       "IPY_MODEL_826164ddb8614be1af2f60a8d8571f3c",
       "IPY_MODEL_f723078ee8dd4ff9bd54de4ddf8f1d48"
      ],
      "layout": "IPY_MODEL_e4dac47697f34275b8b4ba70247efa2f"
     }
    },
    "15afa0cc59494ff78d84b269c9846ab7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91f3423669084cf38cc7cf5aa66fc3b6",
      "placeholder": "​",
      "style": "IPY_MODEL_76e954c932e84eddb4760a8e68dfa924",
      "value": "100%"
     }
    },
    "826164ddb8614be1af2f60a8d8571f3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbeca938736049da95235a9df798dd50",
      "max": 346663984,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f90a42c5482f433bb01b93be2e3bf370",
      "value": 346663984
     }
    },
    "f723078ee8dd4ff9bd54de4ddf8f1d48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7e5e32f65834131b3f379f2e26651f8",
      "placeholder": "​",
      "style": "IPY_MODEL_0dde9b6bea3b493ab10f15550990d2bf",
      "value": " 331M/331M [00:14&lt;00:00, 30.0MB/s]"
     }
    },
    "e4dac47697f34275b8b4ba70247efa2f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91f3423669084cf38cc7cf5aa66fc3b6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76e954c932e84eddb4760a8e68dfa924": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbeca938736049da95235a9df798dd50": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f90a42c5482f433bb01b93be2e3bf370": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7e5e32f65834131b3f379f2e26651f8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0dde9b6bea3b493ab10f15550990d2bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RcyxmRJGqlY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Практика №4\n",
    "\n",
    "Теперь мы построим и обучим простую end-to-end модель. Будем работать с пропатченной версией уже готового [пайплайна](https://www.assemblyai.com/blog/end-to-end-speech-recognition-pytorch). Также нам пригодится [ESPnet](https://github.com/espnet/espnet) для использования модели [Transformer](http://jalammar.github.io/illustrated-transformer/) в качестве энкодера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDbO_rrWGq7j",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WzJyomV1JaLp",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "621a2905-815e-478f-d59b-5cf008072662",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!pip install torchaudio"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.11.0+cu113)\n",
      "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchaudio) (4.2.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TROAsHTXHWik",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "34782ecd-472e-4cc6-e2ba-657a46b7b37d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!gdown --id '1skrVbNyrhBLeceGS9CV9uIw_gvo1JiA6'\n",
    "\n",
    "!unzip -q lab4.zip\n",
    "!rm -rf lab4.zip sample_data\n",
    "%cd lab4"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1skrVbNyrhBLeceGS9CV9uIw_gvo1JiA6\n",
      "To: /content/lab4.zip\n",
      "100% 2.77M/2.77M [00:00<00:00, 107MB/s]\n",
      "replace lab4/train_clean_100_text_clean.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
      "/content/lab4\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m4wcCtkIH2dn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from utils import TextTransform\n",
    "from utils import cer\n",
    "from utils import wer\n",
    "\n",
    "from espnet.nets.pytorch_backend.transformer.embedding import PositionalEncoding\n",
    "from espnet.nets.pytorch_backend.transformer.encoder_layer import EncoderLayer\n",
    "from espnet.nets.pytorch_backend.transformer.repeat import repeat\n",
    "from espnet.nets.pytorch_backend.transformer.attention import MultiHeadedAttention\n",
    "from espnet.nets.pytorch_backend.transformer.positionwise_feed_forward import PositionwiseFeedForward\n",
    "from espnet.nets.pytorch_backend.transformer.layer_norm import LayerNorm\n",
    "from espnet.nets.pytorch_backend.nets_utils import make_pad_mask"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "id": "XHKuY8HnAC4M",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8d0d63f7-7906-44fb-a10a-2325626c2820",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wed Jun  1 03:11:22 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   53C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NaESUZiHJgfN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "train_audio_transforms = torch.nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=400, hop_length=160, n_mels=80),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
    ")\n",
    "\n",
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram(sample_rate=16000,\n",
    "                                                              n_fft=400,\n",
    "                                                              hop_length=160,\n",
    "                                                              n_mels=80)\n",
    "\n",
    "text_transform = TextTransform()\n",
    "\n",
    "#-----------------------------TODO №2-----------------------------------\n",
    "# Заменить графемный токенайзер на сабвордовый TextTransformBPE\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (waveform, _, utterance, _, _, _) in data:\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        elif data_type == 'valid':\n",
    "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            raise Exception('data_type should be train or valid')\n",
    "        spectrograms.append(spec)\n",
    "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0])\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = torch.nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths\n",
    "\n",
    "\n",
    "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(text_transform.int_to_text(decode))\n",
    "    return decodes, targets"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9OqoVLnrJsCV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "class TransformerModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=80,\n",
    "        output_size=29,\n",
    "        conv2d_filters=32,\n",
    "        attention_dim=240,\n",
    "        attention_heads=8,\n",
    "        feedforward_dim=512,\n",
    "        num_layers=8,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.conv_in = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(conv2d_filters, conv2d_filters, kernel_size=(3,3), stride=(2,2), padding=(1,1)),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.conv_out = torch.nn.Sequential(\n",
    "            torch.nn.Linear(conv2d_filters * (input_size // 4), attention_dim),\n",
    "            PositionalEncoding(attention_dim, 0.1),\n",
    "        )\n",
    "        positionwise_layer = PositionwiseFeedForward\n",
    "        positionwise_layer_args = (attention_dim, feedforward_dim, dropout)\n",
    "        self.encoder_layer = repeat(\n",
    "            num_layers,\n",
    "            lambda lnum: EncoderLayer(\n",
    "                attention_dim,\n",
    "                MultiHeadedAttention(\n",
    "                    attention_heads, attention_dim, dropout\n",
    "                ),\n",
    "                positionwise_layer(*positionwise_layer_args),\n",
    "                dropout,\n",
    "                normalize_before=True,\n",
    "                concat_after=False,\n",
    "            ),\n",
    "        )\n",
    "        self.after_norm = LayerNorm(attention_dim)\n",
    "        self.final_layer = torch.nn.Linear(attention_dim, output_size)\n",
    "\n",
    "    def forward(self, x, ilens):\n",
    "        x = x.unsqueeze(1)  # (b, c, t, f)\n",
    "        x = self.conv_in(x)\n",
    "        b, c, t, f = x.size()\n",
    "        x = self.conv_out(x.transpose(1, 2).contiguous().view(b, t, c * f))\n",
    "        masks = (~make_pad_mask(ilens)[:, None, :])[:, :, ::4].to(x.device)\n",
    "        x, _ = self.encoder_layer(x, masks)\n",
    "        x = self.after_norm(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.rand(2, 800, 80)\n",
    "model = TransformerModel()\n",
    "output = model(x, [800, 90])\n",
    "print(output.shape)"
   ],
   "metadata": {
    "id": "mhbOKdLLbXHa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2c796978-7303-4987-9f08-1c7bc6ed5623",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 200, 29])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d2p_8IjeKkqq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "\n",
    "    for batch_idx, _data in enumerate(train_loader):\n",
    "        spectrograms, labels, input_lengths, label_lengths = _data \n",
    "        spectrograms, labels = spectrograms[:, :, :,:max(input_lengths)].to(device), labels.to(device) #(batch, 1, feat_dim, time)\n",
    "        spectrograms = spectrograms.squeeze(1).transpose(1,2) # (batch, time, feat_dim,)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(spectrograms, input_lengths)  # (batch, time, n_classes)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "        input_lengths = [x // 4 for x in input_lengths]\n",
    "\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if batch_idx % 500 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tLR: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(spectrograms),\n",
    "                data_len,\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item(),\n",
    "                scheduler.get_last_lr()[0]))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion, epoch, decode=True):\n",
    "    print('\\nevaluating...')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_cer, test_wer = [], []\n",
    "    with torch.no_grad():\n",
    "        for i, _data in enumerate(test_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data \n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "            spectrograms = spectrograms.squeeze(1).transpose(1,2) # (batch time, feat_dim,)\n",
    "            \n",
    "            output = model(spectrograms, input_lengths)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "            input_lengths = [x // 4 for x in input_lengths]\n",
    "\n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "            if decode:\n",
    "              decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "              for j in range(len(decoded_preds)):\n",
    "                  test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
    "                  test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "    if decode:\n",
    "        avg_cer = sum(test_cer)/len(test_cer)\n",
    "        avg_wer = sum(test_wer)/len(test_wer)\n",
    "\n",
    "        print(f\"Test set: Average loss: {test_loss:.4f}, Average CER: {avg_cer:4f} Average WER: {avg_wer:.4f}\\n\")\n",
    "    else:\n",
    "        print(f\"Average loss: {test_loss:.4f}\\n\")"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MzEbtsB1LKsh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def main(learning_rate=1e-5, batch_size=20, test_batch_size=7, epochs=10,\n",
    "        train_url=\"train-clean-100\", test_url=\"test-clean\"):\n",
    "    \n",
    "    hparams = {\n",
    "        \"input_size\": 80,\n",
    "        \"output_size\": 29,\n",
    "        \"conv2d_filters\": 32,\n",
    "        \"attention_dim\": 320,\n",
    "        \"attention_heads\": 8,\n",
    "        \"feedforward_dim\": 1024,\n",
    "        \"num_layers\":10,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    torch.manual_seed(7)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if not os.path.isdir(\"./data\"):\n",
    "        os.makedirs(\"./data\")\n",
    "\n",
    "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
    "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=True,\n",
    "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
    "                                **kwargs)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=test_batch_size,\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "                                **kwargs)\n",
    "\n",
    "    model = TransformerModel(\n",
    "        hparams['input_size'],\n",
    "        hparams['output_size'],\n",
    "        hparams['conv2d_filters'],\n",
    "        hparams['attention_dim'],\n",
    "        hparams['attention_heads'],\n",
    "        hparams['feedforward_dim'],\n",
    "        hparams['num_layers'],\n",
    "        hparams['dropout']).to(device)\n",
    "\n",
    "    print(model)\n",
    "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "    criterion = torch.nn.CTCLoss(blank=28, zero_infinity=False).to(device)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                            steps_per_epoch=int(len(train_loader)),\n",
    "                                            epochs=hparams['epochs'],\n",
    "                                            anneal_strategy='linear')\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        !date\n",
    "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
    "        test(model, device, test_loader, criterion, epoch, decode=not(epoch % 5))"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eExZLsUiLeXk",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "68e7cab740684122a152081c2f5c1d16",
      "29f463fb5f874861908b4c6321b5d357",
      "8d85bf7f668e4ee2bb7f195423b03938",
      "7c72b70da2084161b5fe07559b14c14f",
      "a04e20d12ff54be7b3e2766bbf271786",
      "0d44f4c58cb545dabeead938dc8d7234",
      "3e6306872dca413382c40bf1344718b3",
      "734705263c894bc1b56436c0236bd330",
      "d3bfee4d9ec641db98fa63fbb50ef19f",
      "3c5b6231d8a744b991c4e67f4749a38c",
      "2a329bad709b4dfea8825ff6f837b9b3",
      "a26b892461224607bf240713328f09db",
      "131a9e3341854c13b62cbac41307e1e2",
      "e35d5f449ad24375afc879563189f569",
      "631a22999a6c463f8c21654ea485f8f8",
      "9fcc8a5576034a52954708ca2e92b111",
      "ebdc01d6ef184019847ae9b30995cedf",
      "a0ea973d5d9544ba8176604e5ab31d60",
      "ee499e8fc3594c9b91c1ca2b3471a0b4",
      "32695a0c4c6040dabb3553cbb4c4f468",
      "55b41144ccfd4c0c9c53001e5a4df7e4",
      "bdc25eaef0c84cc293b1ba498555d44e"
     ]
    },
    "outputId": "1a9794e8-4aa7-4f7d-94a1-fbd886f7abe2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 10\n",
    "test_batch_size = 7\n",
    "epochs = 10\n",
    "libri_train_set = \"train-clean-100\"\n",
    "libri_test_set = \"test-clean\"\n",
    "\n",
    "main(learning_rate, batch_size, test_batch_size, epochs, libri_train_set, libri_test_set)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0.00/5.95G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68e7cab740684122a152081c2f5c1d16"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0.00/331M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a26b892461224607bf240713328f09db"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TransformerModel(\n",
      "  (conv_in): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=320, bias=True)\n",
      "    (1): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder_layer): MultiSequential(\n",
      "    (0): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (1): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (2): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (3): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (4): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (5): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (6): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (7): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (8): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (9): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (after_norm): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "  (final_layer): Linear(in_features=320, out_features=29, bias=True)\n",
      ")\n",
      "Num Model Parameters 10913277\n",
      "Mon May 30 06:13:06 UTC 2022\n",
      "Train Epoch: 1 [0/28539 (0%)]\tLoss: 4.720305\tLR: 0.000040\n",
      "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 2.728351\tLR: 0.000096\n",
      "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 2.798616\tLR: 0.000152\n",
      "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 2.565736\tLR: 0.000208\n",
      "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 2.324332\tLR: 0.000264\n",
      "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 2.347218\tLR: 0.000320\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.1901\n",
      "\n",
      "Mon May 30 06:23:53 UTC 2022\n",
      "Train Epoch: 2 [0/28539 (0%)]\tLoss: 2.069399\tLR: 0.000360\n",
      "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 2.233373\tLR: 0.000416\n",
      "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 2.087045\tLR: 0.000472\n",
      "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 2.163724\tLR: 0.000528\n",
      "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 2.014890\tLR: 0.000584\n",
      "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 1.974317\tLR: 0.000640\n",
      "\n",
      "evaluating...\n",
      "Average loss: 1.9084\n",
      "\n",
      "Mon May 30 06:34:42 UTC 2022\n",
      "Train Epoch: 3 [0/28539 (0%)]\tLoss: 2.030144\tLR: 0.000680\n",
      "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 1.968858\tLR: 0.000736\n",
      "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 1.943062\tLR: 0.000792\n",
      "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 1.741912\tLR: 0.000848\n",
      "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 1.828096\tLR: 0.000904\n",
      "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 1.954957\tLR: 0.000961\n",
      "\n",
      "evaluating...\n",
      "Average loss: 1.5680\n",
      "\n",
      "Mon May 30 06:45:29 UTC 2022\n",
      "Train Epoch: 4 [0/28539 (0%)]\tLoss: 1.748682\tLR: 0.001000\n",
      "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 1.580771\tLR: 0.000975\n",
      "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 1.570566\tLR: 0.000950\n",
      "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 1.774663\tLR: 0.000925\n",
      "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 1.543596\tLR: 0.000900\n",
      "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 1.588176\tLR: 0.000875\n",
      "\n",
      "evaluating...\n",
      "Average loss: 1.2289\n",
      "\n",
      "Mon May 30 06:56:17 UTC 2022\n",
      "Train Epoch: 5 [0/28539 (0%)]\tLoss: 1.558147\tLR: 0.000857\n",
      "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 1.376588\tLR: 0.000832\n",
      "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 1.329800\tLR: 0.000807\n",
      "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 1.207287\tLR: 0.000782\n",
      "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 1.571417\tLR: 0.000757\n",
      "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 1.223887\tLR: 0.000732\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 1.0331, Average CER: 0.265861 Average WER: 0.7272\n",
      "\n",
      "Mon May 30 07:12:22 UTC 2022\n",
      "Train Epoch: 6 [0/28539 (0%)]\tLoss: 1.110190\tLR: 0.000714\n",
      "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 1.450137\tLR: 0.000689\n",
      "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 1.348597\tLR: 0.000664\n",
      "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 1.370587\tLR: 0.000639\n",
      "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 1.227234\tLR: 0.000614\n",
      "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 1.202042\tLR: 0.000589\n",
      "\n",
      "evaluating...\n",
      "Average loss: 0.9126\n",
      "\n",
      "Mon May 30 07:23:05 UTC 2022\n",
      "Train Epoch: 7 [0/28539 (0%)]\tLoss: 1.348323\tLR: 0.000571\n",
      "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 1.364820\tLR: 0.000546\n",
      "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 1.265457\tLR: 0.000521\n",
      "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 0.938879\tLR: 0.000496\n",
      "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 1.170074\tLR: 0.000471\n",
      "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 1.171997\tLR: 0.000446\n",
      "\n",
      "evaluating...\n",
      "Average loss: 0.8207\n",
      "\n",
      "Mon May 30 07:33:53 UTC 2022\n",
      "Train Epoch: 8 [0/28539 (0%)]\tLoss: 0.990518\tLR: 0.000428\n",
      "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 1.116365\tLR: 0.000403\n",
      "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 1.260974\tLR: 0.000378\n",
      "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 0.932516\tLR: 0.000353\n",
      "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 1.053072\tLR: 0.000328\n",
      "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 1.143230\tLR: 0.000303\n",
      "\n",
      "evaluating...\n",
      "Average loss: 0.7540\n",
      "\n",
      "Mon May 30 07:44:40 UTC 2022\n",
      "Train Epoch: 9 [0/28539 (0%)]\tLoss: 0.937002\tLR: 0.000286\n",
      "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 0.897332\tLR: 0.000261\n",
      "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 0.943817\tLR: 0.000236\n",
      "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 0.987410\tLR: 0.000211\n",
      "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 1.039402\tLR: 0.000186\n",
      "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 1.102917\tLR: 0.000160\n",
      "\n",
      "evaluating...\n",
      "Average loss: 0.7024\n",
      "\n",
      "Mon May 30 07:55:26 UTC 2022\n",
      "Train Epoch: 10 [0/28539 (0%)]\tLoss: 0.954898\tLR: 0.000143\n",
      "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 0.781514\tLR: 0.000118\n",
      "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 1.000633\tLR: 0.000093\n",
      "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 0.995110\tLR: 0.000068\n",
      "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 0.865871\tLR: 0.000043\n",
      "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 0.881566\tLR: 0.000018\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 0.6744, Average CER: 0.181627 Average WER: 0.5456\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mby39YVqZadd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <b>Задание №1</b> (5 баллов):\n",
    "На данный момент практически все E2E SOTA решения используют [сабворды](https://dyakonov.org/2019/11/29/%D1%82%D0%BE%D0%BA%D0%B5%D0%BD%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F-%D0%BD%D0%B0-%D0%BF%D0%BE%D0%B4%D1%81%D0%BB%D0%BE%D0%B2%D0%B0-subword-tokenization/) (subwords/wordpieces) в качестве таргетов нейронки для распознавания. Нам бы тоже не мешало перейти от графем к сабвордам. Теперь вместо букв (графем) будем распознавать кусочки слов. В качестве такого токенайзера предлагается использовать [Sentencepiece](https://github.com/google/sentencepiece). Пример обучения BPE токенайзера можно найти в [link](https://github.com/google/sentencepiece/tree/master/python). Главное правильно обернуть его в наш класс TextTransformBPE. Текстовый файл (train_clean_100_text_clean.txt) для обучения токенайзера уже подготовлен и лежит в корневой папке проекта. "
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install sentencepiece"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmrsbDtjBYVq",
    "outputId": "fd916bb1-f464-4aa7-e5cb-416a79b9b142",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import sentencepiece as spm"
   ],
   "metadata": {
    "id": "4ZILx1H7mM9x",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JNbiW919e2le",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "class TextTransformBPE:\n",
    "    def __init__(self, train_text, vocab_size: int = 2000, model_type: str = \"bpe\", ):\n",
    "        \"\"\" Обучение BPE модели на 2000 юнитов\"\"\"\n",
    "        spm.SentencePieceTrainer.train(\n",
    "            input=train_text, model_prefix='model',\n",
    "            vocab_size=vocab_size, model_type=model_type,\n",
    "            normalization_rule_name='nfkc_cf'\n",
    "        )\n",
    "        self.model = spm.SentencePieceProcessor(model_file='model.model')\n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Преобразование входного текста в последовательность сабвордов в формате их индекса в BPE модели \"\"\"\n",
    "        int_sequence = self.model.encode(text)\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Преобразование последовательности индексов сабвордов в текст \"\"\"\n",
    "        labels = list(map(int, labels))\n",
    "        string = self.model.decode(labels)\n",
    "        return string"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 10\n",
    "test_batch_size = 7\n",
    "epochs = 10\n",
    "libri_train_set = \"train-clean-100\"\n",
    "libri_test_set = \"test-clean\"\n",
    "\n",
    "text_transform = TextTransformBPE(train_text='train_clean_100_text_clean.txt')"
   ],
   "metadata": {
    "id": "5-EBLL-6od6K",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def main(learning_rate=1e-5, batch_size=20, test_batch_size=7, epochs=10,\n",
    "        train_url=\"train-clean-100\", test_url=\"test-clean\"):\n",
    "    \n",
    "    hparams = {\n",
    "        \"input_size\": 80,\n",
    "        \"output_size\": 2000,\n",
    "        \"conv2d_filters\": 32,\n",
    "        \"attention_dim\": 320,\n",
    "        \"attention_heads\": 8,\n",
    "        \"feedforward_dim\": 1024,\n",
    "        \"num_layers\":10,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    torch.manual_seed(7)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if not os.path.isdir(\"./data\"):\n",
    "        os.makedirs(\"./data\")\n",
    "\n",
    "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
    "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=True,\n",
    "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
    "                                **kwargs)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=test_batch_size,\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "                                **kwargs)\n",
    "\n",
    "    model = TransformerModel(\n",
    "        hparams['input_size'],\n",
    "        hparams['output_size'],\n",
    "        hparams['conv2d_filters'],\n",
    "        hparams['attention_dim'],\n",
    "        hparams['attention_heads'],\n",
    "        hparams['feedforward_dim'],\n",
    "        hparams['num_layers'],\n",
    "        hparams['dropout']).to(device)\n",
    "\n",
    "    print(model)\n",
    "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "    criterion = torch.nn.CTCLoss(blank=28, zero_infinity=False).to(device)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                            steps_per_epoch=int(len(train_loader)),\n",
    "                                            epochs=hparams['epochs'],\n",
    "                                            anneal_strategy='linear')\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        !date\n",
    "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
    "        test(model, device, test_loader, criterion, epoch, decode=not(epoch % 5))"
   ],
   "metadata": {
    "id": "rGkJfgFOWG2D",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "main(learning_rate, batch_size, test_batch_size, epochs, libri_train_set, libri_test_set)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xf_Q4YJacV1f",
    "outputId": "ef418176-1146-4546-94bf-2ed98e59bb09",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TransformerModel(\n",
      "  (conv_in): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=320, bias=True)\n",
      "    (1): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder_layer): MultiSequential(\n",
      "    (0): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (1): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (2): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (3): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (4): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (5): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (6): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (7): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (8): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (9): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (after_norm): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "  (final_layer): Linear(in_features=320, out_features=2000, bias=True)\n",
      ")\n",
      "Num Model Parameters 11545968\n",
      "Tue May 31 13:42:21 UTC 2022\n",
      "Train Epoch: 1 [0/28539 (0%)]\tLoss: 46.106350\tLR: 0.000040\n",
      "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 6.687394\tLR: 0.000096\n",
      "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 6.619082\tLR: 0.000152\n",
      "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 6.516578\tLR: 0.000208\n",
      "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 6.513318\tLR: 0.000264\n",
      "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 6.448166\tLR: 0.000320\n",
      "\n",
      "evaluating...\n",
      "Average loss: 6.0109\n",
      "\n",
      "Tue May 31 13:53:23 UTC 2022\n",
      "Train Epoch: 2 [0/28539 (0%)]\tLoss: 6.063124\tLR: 0.000360\n",
      "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 5.736186\tLR: 0.000416\n",
      "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 5.430805\tLR: 0.000472\n",
      "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 5.294462\tLR: 0.000528\n",
      "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 4.966045\tLR: 0.000584\n",
      "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 5.043467\tLR: 0.000640\n",
      "\n",
      "evaluating...\n",
      "Average loss: 4.4945\n",
      "\n",
      "Tue May 31 14:04:25 UTC 2022\n",
      "Train Epoch: 3 [0/28539 (0%)]\tLoss: 4.799948\tLR: 0.000680\n",
      "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 4.849342\tLR: 0.000736\n",
      "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 4.651868\tLR: 0.000792\n",
      "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 4.808876\tLR: 0.000848\n",
      "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 4.658764\tLR: 0.000904\n",
      "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 4.376767\tLR: 0.000961\n",
      "\n",
      "evaluating...\n",
      "Average loss: 4.0041\n",
      "\n",
      "Tue May 31 14:15:27 UTC 2022\n",
      "Train Epoch: 4 [0/28539 (0%)]\tLoss: 4.423294\tLR: 0.001000\n",
      "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 4.203199\tLR: 0.000975\n",
      "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 3.938967\tLR: 0.000950\n",
      "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 4.294973\tLR: 0.000925\n",
      "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 3.877550\tLR: 0.000900\n",
      "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 4.347558\tLR: 0.000875\n",
      "\n",
      "evaluating...\n",
      "Average loss: 3.3965\n",
      "\n",
      "Tue May 31 14:26:27 UTC 2022\n",
      "Train Epoch: 5 [0/28539 (0%)]\tLoss: 3.582809\tLR: 0.000857\n",
      "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 3.923479\tLR: 0.000832\n",
      "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 3.782185\tLR: 0.000807\n",
      "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 3.446933\tLR: 0.000782\n",
      "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 3.120979\tLR: 0.000757\n",
      "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 3.062835\tLR: 0.000732\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 2.7479, Average CER: 0.398683 Average WER: 0.6393\n",
      "\n",
      "Tue May 31 14:42:19 UTC 2022\n",
      "Train Epoch: 6 [0/28539 (0%)]\tLoss: 3.277358\tLR: 0.000714\n",
      "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 3.151613\tLR: 0.000689\n",
      "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 3.173730\tLR: 0.000664\n",
      "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 2.868566\tLR: 0.000639\n",
      "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 2.553573\tLR: 0.000614\n",
      "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 2.921641\tLR: 0.000589\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.3661\n",
      "\n",
      "Tue May 31 14:53:21 UTC 2022\n",
      "Train Epoch: 7 [0/28539 (0%)]\tLoss: 3.052249\tLR: 0.000571\n",
      "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 2.830995\tLR: 0.000546\n",
      "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 2.887905\tLR: 0.000521\n",
      "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 2.510773\tLR: 0.000496\n",
      "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 3.109904\tLR: 0.000471\n",
      "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 2.699490\tLR: 0.000446\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.1259\n",
      "\n",
      "Tue May 31 15:04:23 UTC 2022\n",
      "Train Epoch: 8 [0/28539 (0%)]\tLoss: 2.689584\tLR: 0.000428\n",
      "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 2.907856\tLR: 0.000403\n",
      "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 2.201212\tLR: 0.000378\n",
      "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 2.569399\tLR: 0.000353\n",
      "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 2.415176\tLR: 0.000328\n",
      "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 2.426367\tLR: 0.000303\n",
      "\n",
      "evaluating...\n",
      "Average loss: 1.9521\n",
      "\n",
      "Tue May 31 15:15:26 UTC 2022\n",
      "Train Epoch: 9 [0/28539 (0%)]\tLoss: 2.710471\tLR: 0.000286\n",
      "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 2.061261\tLR: 0.000261\n",
      "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 2.393839\tLR: 0.000236\n",
      "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 2.106327\tLR: 0.000211\n",
      "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 2.379474\tLR: 0.000186\n",
      "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 2.664000\tLR: 0.000160\n",
      "\n",
      "evaluating...\n",
      "Average loss: 1.8300\n",
      "\n",
      "Tue May 31 15:26:24 UTC 2022\n",
      "Train Epoch: 10 [0/28539 (0%)]\tLoss: 2.602625\tLR: 0.000143\n",
      "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 2.011208\tLR: 0.000118\n",
      "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 2.552206\tLR: 0.000093\n",
      "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 2.293554\tLR: 0.000068\n",
      "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 2.104522\tLR: 0.000043\n",
      "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 2.370805\tLR: 0.000018\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 1.7712, Average CER: 0.263555 Average WER: 0.4846\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Ответ**:\n",
    "The average WER: 0.4846 is lower for BPE transformation compared to the previous model with average WER: 0.5456, however, it has a drawback since the average CER: 0.263555 is higher for BPE compared to the previous model with average CER: 0.181627"
   ],
   "metadata": {
    "id": "gFS3PNxEAUiK",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gV48Q7HqZsAD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <b>Задание №2</b> (5 баллов):\n",
    "Импровизация по улучшению качества распознавания."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 20\n",
    "test_batch_size = 7\n",
    "epochs = 10\n",
    "libri_train_set = \"train-clean-100\"\n",
    "libri_test_set = \"test-clean\"\n",
    "\n",
    "text_transform = TextTransformBPE(train_text='train_clean_100_text_clean.txt', vocab_size=5000)"
   ],
   "metadata": {
    "id": "crok6F02xqVB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def main(learning_rate=1e-5, batch_size=20, test_batch_size=7, epochs=10,\n",
    "        train_url=\"train-clean-100\", test_url=\"test-clean\"):\n",
    "    \n",
    "    hparams = {\n",
    "        \"input_size\": 80,\n",
    "        \"output_size\": 5000,\n",
    "        \"conv2d_filters\": 32,\n",
    "        \"attention_dim\": 320,\n",
    "        \"attention_heads\": 8,\n",
    "        \"feedforward_dim\": 1024,\n",
    "        \"num_layers\":10,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    torch.manual_seed(7)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if not os.path.isdir(\"./data\"):\n",
    "        os.makedirs(\"./data\")\n",
    "\n",
    "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
    "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=True,\n",
    "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
    "                                **kwargs)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=test_batch_size,\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "                                **kwargs)\n",
    "\n",
    "    model = TransformerModel(\n",
    "        hparams['input_size'],\n",
    "        hparams['output_size'],\n",
    "        hparams['conv2d_filters'],\n",
    "        hparams['attention_dim'],\n",
    "        hparams['attention_heads'],\n",
    "        hparams['feedforward_dim'],\n",
    "        hparams['num_layers'],\n",
    "        hparams['dropout']).to(device)\n",
    "\n",
    "    print(model)\n",
    "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "    criterion = torch.nn.CTCLoss(blank=28, zero_infinity=False).to(device)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                            steps_per_epoch=int(len(train_loader)),\n",
    "                                            epochs=hparams['epochs'],\n",
    "                                            anneal_strategy='linear')\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        !date\n",
    "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
    "        test(model, device, test_loader, criterion, epoch, decode=not(epoch % 5))"
   ],
   "metadata": {
    "id": "HjfaCNGWxuaX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "main(learning_rate, batch_size, test_batch_size, epochs, libri_train_set, libri_test_set)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2c38207ef5384c2886ba2fdd60c76345",
      "86418589e09e4ff88273f9566bc5a572",
      "621646e6502944978fbe3245a5b9bd26",
      "53ea2ec7c43b40de9c29ea5d0dd48051",
      "5c5a7aeb1f1b4180bb5d0148e09992ca",
      "e5d3e2a726fe4a9aae02ecbb72c22994",
      "1e5858381d234fceab7cf558817ff7f7",
      "9dce63c148d642578794061ded216d68",
      "3b743bca428241f8a0973a4ca9371ed7",
      "ef06afea9f4d48cdb5b7a8cf3800feb8",
      "795d3831083748a6a8ad8f8f767bc549",
      "faae1db38242454fa5003c3c3e8e229a",
      "15afa0cc59494ff78d84b269c9846ab7",
      "826164ddb8614be1af2f60a8d8571f3c",
      "f723078ee8dd4ff9bd54de4ddf8f1d48",
      "e4dac47697f34275b8b4ba70247efa2f",
      "91f3423669084cf38cc7cf5aa66fc3b6",
      "76e954c932e84eddb4760a8e68dfa924",
      "bbeca938736049da95235a9df798dd50",
      "f90a42c5482f433bb01b93be2e3bf370",
      "b7e5e32f65834131b3f379f2e26651f8",
      "0dde9b6bea3b493ab10f15550990d2bf"
     ]
    },
    "id": "3gG_y32UnP5A",
    "outputId": "55ab32f1-7fda-45ed-94e2-aa7aa3f7ad89",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0.00/5.95G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c38207ef5384c2886ba2fdd60c76345"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0.00/331M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "faae1db38242454fa5003c3c3e8e229a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TransformerModel(\n",
      "  (conv_in): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=320, bias=True)\n",
      "    (1): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder_layer): MultiSequential(\n",
      "    (0): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (1): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (2): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (3): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (4): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (5): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (6): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (7): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (8): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (9): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (after_norm): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "  (final_layer): Linear(in_features=320, out_features=5000, bias=True)\n",
      ")\n",
      "Num Model Parameters 12508968\n",
      "Wed Jun  1 00:19:31 UTC 2022\n",
      "Train Epoch: 1 [0/28539 (0%)]\tLoss: 58.226807\tLR: 0.000040\n",
      "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 6.901677\tLR: 0.000152\n",
      "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 6.960356\tLR: 0.000265\n",
      "\n",
      "evaluating...\n",
      "Average loss: 6.9516\n",
      "\n",
      "Wed Jun  1 00:30:38 UTC 2022\n",
      "Train Epoch: 2 [0/28539 (0%)]\tLoss: 7.089694\tLR: 0.000360\n",
      "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 6.755501\tLR: 0.000472\n",
      "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 5.905112\tLR: 0.000585\n",
      "\n",
      "evaluating...\n",
      "Average loss: 5.4384\n",
      "\n",
      "Wed Jun  1 00:41:49 UTC 2022\n",
      "Train Epoch: 3 [0/28539 (0%)]\tLoss: 5.624988\tLR: 0.000680\n",
      "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 5.512199\tLR: 0.000793\n",
      "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 5.088206\tLR: 0.000905\n",
      "\n",
      "evaluating...\n",
      "Average loss: 4.5498\n",
      "\n",
      "Wed Jun  1 00:53:00 UTC 2022\n",
      "Train Epoch: 4 [0/28539 (0%)]\tLoss: 4.933919\tLR: 0.001000\n",
      "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 4.553369\tLR: 0.000950\n",
      "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 4.847689\tLR: 0.000900\n",
      "\n",
      "evaluating...\n",
      "Average loss: 4.0654\n",
      "\n",
      "Wed Jun  1 01:04:11 UTC 2022\n",
      "Train Epoch: 5 [0/28539 (0%)]\tLoss: 4.146882\tLR: 0.000857\n",
      "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 4.186073\tLR: 0.000807\n",
      "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 3.912341\tLR: 0.000757\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 3.3064, Average CER: 0.485805 Average WER: 0.6632\n",
      "\n",
      "Wed Jun  1 01:19:41 UTC 2022\n",
      "Train Epoch: 6 [0/28539 (0%)]\tLoss: 3.835140\tLR: 0.000714\n",
      "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 3.354572\tLR: 0.000664\n",
      "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 3.676020\tLR: 0.000614\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.8174\n",
      "\n",
      "Wed Jun  1 01:30:51 UTC 2022\n",
      "Train Epoch: 7 [0/28539 (0%)]\tLoss: 3.157681\tLR: 0.000571\n",
      "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 3.066543\tLR: 0.000521\n",
      "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 3.212589\tLR: 0.000471\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.5354\n",
      "\n",
      "Wed Jun  1 01:42:02 UTC 2022\n",
      "Train Epoch: 8 [0/28539 (0%)]\tLoss: 2.780821\tLR: 0.000428\n",
      "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 2.912791\tLR: 0.000378\n",
      "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 3.105212\tLR: 0.000328\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.3576\n",
      "\n",
      "Wed Jun  1 01:53:12 UTC 2022\n",
      "Train Epoch: 9 [0/28539 (0%)]\tLoss: 2.744987\tLR: 0.000286\n",
      "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 2.689707\tLR: 0.000235\n",
      "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 2.542505\tLR: 0.000185\n",
      "\n",
      "evaluating...\n",
      "Average loss: 2.2296\n",
      "\n",
      "Wed Jun  1 02:04:21 UTC 2022\n",
      "Train Epoch: 10 [0/28539 (0%)]\tLoss: 2.315638\tLR: 0.000143\n",
      "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 2.545394\tLR: 0.000093\n",
      "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 2.510046\tLR: 0.000043\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 2.1660, Average CER: 0.309763 Average WER: 0.4841\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size = 10\n",
    "test_batch_size = 7\n",
    "epochs = 10\n",
    "libri_train_set = \"train-clean-100\"\n",
    "libri_test_set = \"test-clean\"\n",
    "\n",
    "text_transform = TextTransformBPE(train_text='train_clean_100_text_clean.txt', vocab_size=3000)"
   ],
   "metadata": {
    "id": "BvRP4ojpJCcx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def main(learning_rate=1e-5, batch_size=20, test_batch_size=7, epochs=10,\n",
    "        train_url=\"train-clean-100\", test_url=\"test-clean\"):\n",
    "    \n",
    "    hparams = {\n",
    "        \"input_size\": 80,\n",
    "        \"output_size\": 3000,\n",
    "        \"conv2d_filters\": 32,\n",
    "        \"attention_dim\": 320,\n",
    "        \"attention_heads\": 8,\n",
    "        \"feedforward_dim\": 1024,\n",
    "        \"num_layers\":12,\n",
    "        \"dropout\": 0.2,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    torch.manual_seed(7)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if not os.path.isdir(\"./data\"):\n",
    "        os.makedirs(\"./data\")\n",
    "\n",
    "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
    "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=True,\n",
    "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
    "                                **kwargs)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=test_batch_size,\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "                                **kwargs)\n",
    "\n",
    "    model = TransformerModel(\n",
    "        hparams['input_size'],\n",
    "        hparams['output_size'],\n",
    "        hparams['conv2d_filters'],\n",
    "        hparams['attention_dim'],\n",
    "        hparams['attention_heads'],\n",
    "        hparams['feedforward_dim'],\n",
    "        hparams['num_layers'],\n",
    "        hparams['dropout']).to(device)\n",
    "\n",
    "    print(model)\n",
    "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "    criterion = torch.nn.CTCLoss(blank=28, zero_infinity=False).to(device)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                            steps_per_epoch=int(len(train_loader)),\n",
    "                                            epochs=hparams['epochs'],\n",
    "                                            anneal_strategy='linear')\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        !date\n",
    "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch)\n",
    "        test(model, device, test_loader, criterion, epoch, decode=not(epoch % 5))"
   ],
   "metadata": {
    "id": "O4pWgQqlJAAz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "main(learning_rate, batch_size, test_batch_size, epochs, libri_train_set, libri_test_set)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhU-FeOUJcfp",
    "outputId": "955282f3-5be7-4bf9-f94c-b5f5c71adf78",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TransformerModel(\n",
      "  (conv_in): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv_out): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=320, bias=True)\n",
      "    (1): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (encoder_layer): MultiSequential(\n",
      "    (0): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (1): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (2): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (3): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (4): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (5): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (6): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (7): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (8): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (9): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (10): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "    (11): EncoderLayer(\n",
      "      (self_attn): MultiHeadedAttention(\n",
      "        (linear_q): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_k): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_v): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (linear_out): Linear(in_features=320, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (feed_forward): PositionwiseFeedForward(\n",
      "        (w_1): Linear(in_features=320, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=320, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (norm1): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (concat_linear): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (after_norm): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
      "  (final_layer): Linear(in_features=320, out_features=3000, bias=True)\n",
      ")\n",
      "Num Model Parameters 14004696\n",
      "Wed Jun  1 03:12:53 UTC 2022\n",
      "Train Epoch: 1 [0/28539 (0%)]\tLoss: 55.746529\tLR: 0.000004\n",
      "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 7.267120\tLR: 0.000010\n",
      "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 6.821672\tLR: 0.000015\n",
      "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 6.715003\tLR: 0.000021\n",
      "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 6.921208\tLR: 0.000026\n",
      "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 6.852906\tLR: 0.000032\n",
      "\n",
      "evaluating...\n",
      "Average loss: 6.8327\n",
      "\n",
      "Wed Jun  1 03:25:57 UTC 2022\n",
      "Train Epoch: 2 [0/28539 (0%)]\tLoss: 6.651220\tLR: 0.000036\n",
      "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 6.691989\tLR: 0.000042\n",
      "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 6.710310\tLR: 0.000047\n",
      "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 6.718435\tLR: 0.000053\n",
      "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 6.774727\tLR: 0.000058\n",
      "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 6.848874\tLR: 0.000064\n",
      "\n",
      "evaluating...\n",
      "Average loss: 6.7578\n",
      "\n",
      "Wed Jun  1 03:39:02 UTC 2022\n",
      "Train Epoch: 3 [0/28539 (0%)]\tLoss: 6.845306\tLR: 0.000068\n",
      "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 6.479330\tLR: 0.000074\n",
      "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 6.720231\tLR: 0.000079\n",
      "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 6.629630\tLR: 0.000085\n",
      "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 6.487720\tLR: 0.000090\n",
      "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 6.309955\tLR: 0.000096\n",
      "\n",
      "evaluating...\n",
      "Average loss: 6.1564\n",
      "\n",
      "Wed Jun  1 03:52:08 UTC 2022\n",
      "Train Epoch: 4 [0/28539 (0%)]\tLoss: 6.221467\tLR: 0.000100\n",
      "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 6.135915\tLR: 0.000097\n",
      "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 5.938217\tLR: 0.000095\n",
      "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 5.742664\tLR: 0.000092\n",
      "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 5.758544\tLR: 0.000090\n",
      "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 5.776635\tLR: 0.000087\n",
      "\n",
      "evaluating...\n",
      "Average loss: 5.3463\n",
      "\n",
      "Wed Jun  1 04:05:16 UTC 2022\n",
      "Train Epoch: 5 [0/28539 (0%)]\tLoss: 5.594193\tLR: 0.000086\n",
      "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 5.706923\tLR: 0.000083\n",
      "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 5.653796\tLR: 0.000081\n",
      "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 5.279493\tLR: 0.000078\n",
      "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 5.433088\tLR: 0.000076\n",
      "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 5.154928\tLR: 0.000073\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 4.9043, Average CER: 0.813283 Average WER: 0.8983\n",
      "\n",
      "Wed Jun  1 04:19:57 UTC 2022\n",
      "Train Epoch: 6 [0/28539 (0%)]\tLoss: 5.407266\tLR: 0.000071\n",
      "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 5.212722\tLR: 0.000069\n",
      "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 5.318301\tLR: 0.000066\n",
      "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 4.968679\tLR: 0.000064\n",
      "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 5.001010\tLR: 0.000061\n",
      "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 4.887672\tLR: 0.000059\n",
      "\n",
      "evaluating...\n",
      "Average loss: 4.6546\n",
      "\n",
      "Wed Jun  1 04:33:04 UTC 2022\n",
      "Train Epoch: 7 [0/28539 (0%)]\tLoss: 5.039735\tLR: 0.000057\n",
      "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 5.203773\tLR: 0.000055\n",
      "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 4.549304\tLR: 0.000052\n",
      "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 4.929745\tLR: 0.000050\n",
      "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 4.842069\tLR: 0.000047\n",
      "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 5.136250\tLR: 0.000045\n",
      "\n",
      "evaluating...\n",
      "Average loss: 4.4929\n",
      "\n",
      "Wed Jun  1 04:46:11 UTC 2022\n",
      "Train Epoch: 8 [0/28539 (0%)]\tLoss: 4.623256\tLR: 0.000043\n",
      "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 5.146299\tLR: 0.000040\n",
      "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 5.122872\tLR: 0.000038\n",
      "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 4.578490\tLR: 0.000035\n",
      "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 5.116542\tLR: 0.000033\n",
      "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 4.988727\tLR: 0.000030\n",
      "\n",
      "evaluating...\n",
      "Average loss: 4.4015\n",
      "\n",
      "Wed Jun  1 04:59:18 UTC 2022\n",
      "Train Epoch: 9 [0/28539 (0%)]\tLoss: 4.450592\tLR: 0.000029\n",
      "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 4.753961\tLR: 0.000026\n",
      "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 4.391309\tLR: 0.000024\n",
      "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 4.708654\tLR: 0.000021\n",
      "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 4.830808\tLR: 0.000019\n",
      "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 4.661290\tLR: 0.000016\n",
      "\n",
      "evaluating...\n",
      "Average loss: 4.3244\n",
      "\n",
      "Wed Jun  1 05:12:25 UTC 2022\n",
      "Train Epoch: 10 [0/28539 (0%)]\tLoss: 4.771883\tLR: 0.000014\n",
      "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 4.730391\tLR: 0.000012\n",
      "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 4.524670\tLR: 0.000009\n",
      "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 4.670638\tLR: 0.000007\n",
      "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 4.809001\tLR: 0.000004\n",
      "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 4.868711\tLR: 0.000002\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 4.3019, Average CER: 0.729354 Average WER: 0.8368\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Ответ**:\n",
    "The average WER: 0.4841 is lower compared to the previous model with average WER: 0.4846. The average CER: 0.309763 is higher compared to the previous model with average CER: 0.263555, so we can conclude that the dictionary size 5000 help to improve a little bit the score. The model subwords are used, the higher CER error, but the average WER is little bit lower. Also tried to increase number of layer, and reduce the vocabulary size with lr, but looks like it did not help to improve the model: Average CER: 0.729354 Average WER: 0.8368."
   ],
   "metadata": {
    "id": "N1OBVhLgATV_",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}